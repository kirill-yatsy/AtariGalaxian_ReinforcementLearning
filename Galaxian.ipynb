{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 00:31:29.340084: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-15 00:31:29.371740: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-15 00:31:29.865417: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gymnasium \n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "import os\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from typing import Any\n",
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Any\n",
    "from typing import Dict\n",
    "\n",
    " \n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIALS = 100\n",
    "N_STARTUP_TRIALS = 5\n",
    "N_EVALUATIONS = 2\n",
    "N_TIMESTEPS = int(2e4)\n",
    "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
    "N_EVAL_EPISODES = 3\n",
    "\n",
    "ENV_ID = \"ALE/Galaxian-v5\"\n",
    "\n",
    "DEFAULT_HYPERPARAMS = {\n",
    "    \"policy\": \"MlpPolicy\",\n",
    "    \"buffer_size\": 10000,\n",
    "    \"env\": ENV_ID,\n",
    "    \"seed\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_a2c_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 1, log=True)\n",
    "    gamma = 1.0 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True)\n",
    "    \n",
    "    return { \n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"gamma\": gamma,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrialEvalCallback(EvalCallback):\n",
    "    \"\"\"Callback used for evaluating and reporting a trial.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_env: gymnasium.Env,\n",
    "        trial: optuna.Trial,\n",
    "        n_eval_episodes: int = 5,\n",
    "        eval_freq: int = 10000,\n",
    "        deterministic: bool = True,\n",
    "        verbose: int = 0,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            eval_env=eval_env,\n",
    "            n_eval_episodes=n_eval_episodes,\n",
    "            eval_freq=eval_freq,\n",
    "            deterministic=deterministic,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.trial = trial\n",
    "        self.eval_idx = 0\n",
    "        self.is_pruned = False\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "            super()._on_step()\n",
    "            self.eval_idx += 1\n",
    "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
    "            # Prune trial if need.\n",
    "            if self.trial.should_prune():\n",
    "                self.is_pruned = True\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
    "    # Sample hyperparameters.\n",
    "    kwargs.update(sample_a2c_params(trial))\n",
    "    # Create the RL model.\n",
    "    model = DQN(**kwargs)\n",
    "    # Create env used for evaluation.\n",
    "    eval_env = Monitor(gymnasium.make(ENV_ID))\n",
    "    # Create the callback that will periodically evaluate and report the performance.\n",
    "    eval_callback = TrialEvalCallback(\n",
    "        eval_env, trial, n_eval_episodes=N_EVAL_EPISODES, eval_freq=EVAL_FREQ, deterministic=True\n",
    "    )\n",
    "\n",
    "    nan_encountered = False\n",
    "    try:\n",
    "        model.learn(N_TIMESTEPS, callback=eval_callback)\n",
    "    except AssertionError as e:\n",
    "        # Sometimes, random hyperparams can generate NaN.\n",
    "        print(e)\n",
    "        nan_encountered = True\n",
    "    finally:\n",
    "        # Free memory.\n",
    "        model.env.close()\n",
    "        eval_env.close()\n",
    "\n",
    "    # Tell the optimizer that the trial failed.\n",
    "    if nan_encountered:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    if eval_callback.is_pruned:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return eval_callback.last_mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 23:54:51,663]\u001b[0m A new study created in memory with name: no-name-dd8efb00-067f-4b18-b356-4dc48faf90ef\u001b[0m\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b3b8880> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b2d07c0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:55:06,304]\u001b[0m Trial 0 finished with value: 540.0 and parameters: {'lr': 0.00010506273044970215, 'gamma': 0.00015488713970968385}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b2d0c40> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f67399ea6a0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:55:18,290]\u001b[0m Trial 1 finished with value: 540.0 and parameters: {'lr': 0.6143876437524028, 'gamma': 0.0026008600492741234}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f67399eadc0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b2d0880>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:55:30,352]\u001b[0m Trial 2 finished with value: 540.0 and parameters: {'lr': 2.064328962242027e-05, 'gamma': 0.0003449346328776704}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b2584f0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b2588e0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:55:42,319]\u001b[0m Trial 3 finished with value: 540.0 and parameters: {'lr': 0.11650753586775908, 'gamma': 0.0022556316343385545}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b2d0f10> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b26f250>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:55:54,150]\u001b[0m Trial 4 finished with value: 540.0 and parameters: {'lr': 0.001384629235621046, 'gamma': 0.00020891713901456302}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b21bd90> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b26d370>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:56:05,943]\u001b[0m Trial 5 finished with value: 540.0 and parameters: {'lr': 2.2382108835540684e-05, 'gamma': 0.04793597269671396}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b26dfa0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b2343d0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:56:17,724]\u001b[0m Trial 6 finished with value: 540.0 and parameters: {'lr': 0.0006929219847444852, 'gamma': 0.00010830702258354294}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b26d910> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b2341f0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:56:29,459]\u001b[0m Trial 7 finished with value: 540.0 and parameters: {'lr': 0.00020201077871960803, 'gamma': 0.000692817381042155}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1d8580> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b234c10>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:56:41,351]\u001b[0m Trial 8 finished with value: 540.0 and parameters: {'lr': 0.01010303376758989, 'gamma': 0.01144736395691702}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1d8ac0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1d8340>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:56:53,243]\u001b[0m Trial 9 finished with value: 540.0 and parameters: {'lr': 0.0001266664847039206, 'gamma': 0.0007293823597215288}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1d7130> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1d7550>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:57:05,112]\u001b[0m Trial 10 finished with value: 540.0 and parameters: {'lr': 0.0066955629469251775, 'gamma': 0.00010073680030188347}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1fd130> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1d79d0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:57:17,188]\u001b[0m Trial 11 finished with value: 540.0 and parameters: {'lr': 0.6907781893871912, 'gamma': 0.0033701866278528954}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1d88b0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1d7220>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:57:29,367]\u001b[0m Trial 12 finished with value: 540.0 and parameters: {'lr': 0.04581162319555241, 'gamma': 0.0018414656858555633}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1fd0a0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1fdb20>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:57:41,546]\u001b[0m Trial 13 finished with value: 540.0 and parameters: {'lr': 0.9997298421867032, 'gamma': 0.006712726758280636}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1d78b0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1d7850>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:57:53,721]\u001b[0m Trial 14 finished with value: 540.0 and parameters: {'lr': 0.0024467503220817837, 'gamma': 0.0007044156745101417}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1ff730> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1fde20>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:58:05,773]\u001b[0m Trial 15 finished with value: 540.0 and parameters: {'lr': 0.0336798702548154, 'gamma': 0.00033578608261565957}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1ffaf0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1ff0a0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:58:17,900]\u001b[0m Trial 16 finished with value: 540.0 and parameters: {'lr': 0.185699933843436, 'gamma': 0.02048554875318951}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1e13d0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1e1760>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:58:29,861]\u001b[0m Trial 17 finished with value: 540.0 and parameters: {'lr': 0.011016376706939422, 'gamma': 0.0013699512975595745}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 2.02GB > 0.50GB\n",
      "  warnings.warn(\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1a6340> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1ff490>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:58:41,808]\u001b[0m Trial 18 finished with value: 540.0 and parameters: {'lr': 0.0005330633011493605, 'gamma': 0.004636393846954212}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1fd310> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1ff910>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:58:53,589]\u001b[0m Trial 19 finished with value: 540.0 and parameters: {'lr': 1.0474189333409546e-05, 'gamma': 0.007114228738199288}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1e18e0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1e12b0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:59:05,333]\u001b[0m Trial 20 finished with value: 540.0 and parameters: {'lr': 0.004764431396491624, 'gamma': 0.001259527490681112}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1fdc40> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b234670>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:59:17,129]\u001b[0m Trial 21 finished with value: 540.0 and parameters: {'lr': 3.6233441268541127e-05, 'gamma': 0.0002804586397565194}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1a6dc0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1ffaf0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:59:28,899]\u001b[0m Trial 22 finished with value: 540.0 and parameters: {'lr': 8.537919552324261e-05, 'gamma': 0.00019868044912493168}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1a6ac0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1fb0d0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:59:40,738]\u001b[0m Trial 23 finished with value: 540.0 and parameters: {'lr': 4.934672271695929e-05, 'gamma': 0.0006458609016384957}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1ff550> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1fb430>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-14 23:59:52,406]\u001b[0m Trial 24 finished with value: 540.0 and parameters: {'lr': 1.0449640417252211e-05, 'gamma': 0.00038085736276542525}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1fbe50> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1fb520>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:00:04,122]\u001b[0m Trial 25 finished with value: 540.0 and parameters: {'lr': 0.00027728397869243354, 'gamma': 0.00014650577911988334}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1e7550> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1fbd00>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:00:15,849]\u001b[0m Trial 26 finished with value: 540.0 and parameters: {'lr': 7.275951581887836e-05, 'gamma': 0.0004277709747317121}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1e7c10> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b194280>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:00:27,611]\u001b[0m Trial 27 finished with value: 540.0 and parameters: {'lr': 0.0002196263799763625, 'gamma': 0.00017188134294479602}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 2.02GB > 0.46GB\n",
      "  warnings.warn(\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b194be0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1e71f0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:00:39,412]\u001b[0m Trial 28 finished with value: 540.0 and parameters: {'lr': 3.575604616333866e-05, 'gamma': 0.0011286041122099875}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1fbe80> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b194c40>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:00:51,146]\u001b[0m Trial 29 finished with value: 540.0 and parameters: {'lr': 0.0009641204853519603, 'gamma': 0.0023955373798295624}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1e7790> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b192310>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:01:02,902]\u001b[0m Trial 30 finished with value: 540.0 and parameters: {'lr': 0.0024531270675624928, 'gamma': 0.0002276691555359107}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b194e20> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b192790>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:01:14,831]\u001b[0m Trial 31 finished with value: 540.0 and parameters: {'lr': 0.2846349600131569, 'gamma': 0.0026411025999473516}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1c61f0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b194fa0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:01:26,929]\u001b[0m Trial 32 finished with value: 540.0 and parameters: {'lr': 2.165627452885608e-05, 'gamma': 0.0018297377851187973}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 2.02GB > 0.40GB\n",
      "  warnings.warn(\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1c6970> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1c6820>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:01:39,174]\u001b[0m Trial 33 finished with value: 540.0 and parameters: {'lr': 0.14202999985132228, 'gamma': 0.00014651288882770407}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1c6bb0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1c9490>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:01:51,776]\u001b[0m Trial 34 finished with value: 540.0 and parameters: {'lr': 0.00046878560777551367, 'gamma': 0.00046660591716186385}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 2.02GB > 0.23GB\n",
      "  warnings.warn(\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1c9c70> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1c6af0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:02:04,241]\u001b[0m Trial 35 finished with value: 540.0 and parameters: {'lr': 0.0015981016991779508, 'gamma': 0.00022479920026368915}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1c69a0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1c9f70>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:02:16,500]\u001b[0m Trial 36 finished with value: 540.0 and parameters: {'lr': 0.4641015744887632, 'gamma': 0.0010289844480546892}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1e7040> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1e7820>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:02:28,678]\u001b[0m Trial 37 finished with value: 540.0 and parameters: {'lr': 0.00011801073540128923, 'gamma': 0.00011318333147210986}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1a6850> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1e7d90>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:02:41,050]\u001b[0m Trial 38 finished with value: 540.0 and parameters: {'lr': 0.09340325722066294, 'gamma': 0.00029244446831411025}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1c62b0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b192220>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:02:53,238]\u001b[0m Trial 39 finished with value: 540.0 and parameters: {'lr': 0.9412126620240945, 'gamma': 0.0005560407435450632}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1c63d0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1a6e20>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:03:05,513]\u001b[0m Trial 40 finished with value: 540.0 and parameters: {'lr': 0.3145161663153675, 'gamma': 0.0008680874240395693}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1c6f40> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1e1880>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:03:17,857]\u001b[0m Trial 41 finished with value: 540.0 and parameters: {'lr': 0.00014861069959209037, 'gamma': 0.00010017265416885209}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b19f160> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1e7790>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:03:30,515]\u001b[0m Trial 42 finished with value: 540.0 and parameters: {'lr': 0.001015996431126759, 'gamma': 0.0005041593970908078}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b19f940> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b19f6a0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:03:42,721]\u001b[0m Trial 43 finished with value: 540.0 and parameters: {'lr': 0.01640195608443761, 'gamma': 0.0003195379495771008}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1fd700> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1bb4f0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:03:55,134]\u001b[0m Trial 44 finished with value: 540.0 and parameters: {'lr': 0.5293175075332922, 'gamma': 0.0002394114860449705}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1bbd30> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1e11f0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:04:07,628]\u001b[0m Trial 45 finished with value: 540.0 and parameters: {'lr': 0.00036566008943601195, 'gamma': 0.0036100713143242063}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1be310> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1bb850>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:04:20,221]\u001b[0m Trial 46 finished with value: 540.0 and parameters: {'lr': 0.060982865054452946, 'gamma': 0.0007258109117610316}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1bea30> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1d3130>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:04:32,576]\u001b[0m Trial 47 finished with value: 540.0 and parameters: {'lr': 0.021895500324049792, 'gamma': 0.00016114669642027424}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1d3970> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1be5e0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:04:44,968]\u001b[0m Trial 48 finished with value: 540.0 and parameters: {'lr': 0.0037123558764730743, 'gamma': 0.0016891599307619263}. Best is trial 0 with value: 540.0.\u001b[0m\n",
      "/home/lex/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f673b1bb0d0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f673b1be910>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "\u001b[32m[I 2023-05-15 00:04:57,216]\u001b[0m Trial 49 finished with value: 540.0 and parameters: {'lr': 0.005040009283358013, 'gamma': 0.00037337710957446093}. Best is trial 0 with value: 540.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  50\n",
      "Best trial:\n",
      "  Value:  540.0\n",
      "  Params: \n",
      "    lr: 0.00010506273044970215\n",
      "    gamma: 0.00015488713970968385\n",
      "  User attrs:\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(1)\n",
    "\n",
    "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
    "    # Do not prune before 1/3 of the max budget is used.\n",
    "pruner = MedianPruner(n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3)\n",
    "\n",
    "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
    "try:\n",
    "    study.optimize(objective, n_trials=N_TRIALS, timeout=600)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "print(\"  User attrs:\")\n",
    "for key, value in trial.user_attrs.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env_id = \"ALE/Galaxian-v5\"\n",
    "env = gymnasium.make(env_id)\n",
    "\n",
    "# Env used only for evaluation\n",
    "eval_envs = make_vec_env(env_id, n_envs=2)\n",
    "# 4000 training timesteps\n",
    "budget_pendulum = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549937a2bee84f5cabeb5b60cdf32414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7f5076e297c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = DQN(\"MlpPolicy\", env, seed=0, verbose=0, buffer_size = 10000, learning_rate=0.00010506273044970215, gamma=0.00015488713970968385, )\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=500000, progress_bar=True, tb_log_name = \"DQN\", log_interval=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO Mean episode reward: 540.00 +/- 0.00\n"
     ]
    }
   ],
   "source": [
    "# model = DQN.load(\"DQN_cartpole\", env=env, verbose=1, buffer_size=4)\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100, deterministic=True)\n",
    "print(f\"PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = trial.suggest_float(\"gamma\", 0.9, 0.99999, log=True)\n",
    "max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
    "budget = 20_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"DQN_cartpole\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 427      |\n",
      "|    ep_rew_mean     | 525      |\n",
      "| time/              |          |\n",
      "|    fps             | 728      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 523          |\n",
      "|    ep_rew_mean          | 622          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 492          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044382312 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.79        |\n",
      "|    explained_variance   | 0.000481     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 300          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    value_loss           | 545          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 762         |\n",
      "|    ep_rew_mean          | 858         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 446         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005319806 |\n",
      "|    clip_fraction        | 0.0338      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.000773    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 319         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    value_loss           | 534         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 628         |\n",
      "|    ep_rew_mean          | 715         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 423         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006894185 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 320         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    value_loss           | 605         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 633          |\n",
      "|    ep_rew_mean          | 746          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 400          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071332846 |\n",
      "|    clip_fraction        | 0.0787       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.77        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 350          |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00839     |\n",
      "|    value_loss           | 560          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 611         |\n",
      "|    ep_rew_mean          | 733         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 391         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009585418 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 216         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 638         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 632         |\n",
      "|    ep_rew_mean          | 751         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 384         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007945871 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 251         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    value_loss           | 841         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 591         |\n",
      "|    ep_rew_mean          | 713         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009269001 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 195         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    value_loss           | 534         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 570        |\n",
      "|    ep_rew_mean          | 669        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 380        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 48         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01909944 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.71      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 169        |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.000585  |\n",
      "|    value_loss           | 563        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 592        |\n",
      "|    ep_rew_mean          | 687        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 378        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 54         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00678941 |\n",
      "|    clip_fraction        | 0.0625     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.72      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 279        |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.000795  |\n",
      "|    value_loss           | 443        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 575         |\n",
      "|    ep_rew_mean          | 682         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009167049 |\n",
      "|    clip_fraction        | 0.025       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 218         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00191    |\n",
      "|    value_loss           | 465         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 564         |\n",
      "|    ep_rew_mean          | 662         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009591673 |\n",
      "|    clip_fraction        | 0.06        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 326         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    value_loss           | 725         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 563         |\n",
      "|    ep_rew_mean          | 663         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006179895 |\n",
      "|    clip_fraction        | 0.0682      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 268         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.000718   |\n",
      "|    value_loss           | 418         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 570         |\n",
      "|    ep_rew_mean          | 675         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015451861 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 252         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    value_loss           | 519         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 557          |\n",
      "|    ep_rew_mean          | 658          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075034425 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.66        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 284          |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000836    |\n",
      "|    value_loss           | 569          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 559          |\n",
      "|    ep_rew_mean          | 655          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059950757 |\n",
      "|    clip_fraction        | 0.0809       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.64        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 231          |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    value_loss           | 515          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 570         |\n",
      "|    ep_rew_mean          | 669         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010898141 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 172         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    value_loss           | 427         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 571         |\n",
      "|    ep_rew_mean          | 667         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005369681 |\n",
      "|    clip_fraction        | 0.0629      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 353         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    value_loss           | 533         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 577          |\n",
      "|    ep_rew_mean          | 678          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043586222 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.7         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 246          |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | 0.000309     |\n",
      "|    value_loss           | 521          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 582         |\n",
      "|    ep_rew_mean          | 674         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008581165 |\n",
      "|    clip_fraction        | 0.0284      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 289         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.000239   |\n",
      "|    value_loss           | 547         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 586         |\n",
      "|    ep_rew_mean          | 684         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009649944 |\n",
      "|    clip_fraction        | 0.0413      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    value_loss           | 434         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 584         |\n",
      "|    ep_rew_mean          | 681         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014759856 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 247         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0051     |\n",
      "|    value_loss           | 601         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 581          |\n",
      "|    ep_rew_mean          | 676          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 366          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057032984 |\n",
      "|    clip_fraction        | 0.0701       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.69        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 247          |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.000345    |\n",
      "|    value_loss           | 558          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 583         |\n",
      "|    ep_rew_mean          | 678         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008921516 |\n",
      "|    clip_fraction        | 0.0677      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 311         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00253    |\n",
      "|    value_loss           | 478         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 579          |\n",
      "|    ep_rew_mean          | 675          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 357          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 143          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077598663 |\n",
      "|    clip_fraction        | 0.0758       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.72        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 165          |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 449          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 575         |\n",
      "|    ep_rew_mean          | 670         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 350         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011405958 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 257         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    value_loss           | 502         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 581          |\n",
      "|    ep_rew_mean          | 673          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 349          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086382255 |\n",
      "|    clip_fraction        | 0.0617       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.65        |\n",
      "|    explained_variance   | 1.91e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 283          |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    value_loss           | 682          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 590        |\n",
      "|    ep_rew_mean          | 676        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 348        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 164        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00571798 |\n",
      "|    clip_fraction        | 0.0464     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.63      |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 370        |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.00347   |\n",
      "|    value_loss           | 562        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 596         |\n",
      "|    ep_rew_mean          | 680         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 170         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012823671 |\n",
      "|    clip_fraction        | 0.00801     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -0.00322    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 165         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    value_loss           | 277         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 603          |\n",
      "|    ep_rew_mean          | 681          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 346          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 177          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015708931 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.66        |\n",
      "|    explained_variance   | 0.0175       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 163          |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.000774    |\n",
      "|    value_loss           | 435          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 614         |\n",
      "|    ep_rew_mean          | 693         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 344         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005125137 |\n",
      "|    clip_fraction        | 0.0217      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.0201      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 173         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    value_loss           | 448         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 610           |\n",
      "|    ep_rew_mean          | 688           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 344           |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 190           |\n",
      "|    total_timesteps      | 65536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096585636 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.64         |\n",
      "|    explained_variance   | 0.0674        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 171           |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | -0.00169      |\n",
      "|    value_loss           | 415           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 598          |\n",
      "|    ep_rew_mean          | 677          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 344          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 196          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005200008 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.64        |\n",
      "|    explained_variance   | 0.15         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00053     |\n",
      "|    value_loss           | 382          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 605           |\n",
      "|    ep_rew_mean          | 683           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 344           |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 201           |\n",
      "|    total_timesteps      | 69632         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038186548 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.63         |\n",
      "|    explained_variance   | 0.115         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 297           |\n",
      "|    n_updates            | 330           |\n",
      "|    policy_gradient_loss | -0.000403     |\n",
      "|    value_loss           | 530           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 601          |\n",
      "|    ep_rew_mean          | 677          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 345          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 207          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007099531 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.223        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 246          |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    value_loss           | 496          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 603          |\n",
      "|    ep_rew_mean          | 686          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 345          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 213          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015417943 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.183        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 294          |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    value_loss           | 543          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 609          |\n",
      "|    ep_rew_mean          | 692          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 345          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 219          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008430908 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.211        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 260          |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.000522    |\n",
      "|    value_loss           | 398          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 619          |\n",
      "|    ep_rew_mean          | 704          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 344          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029721227 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.308        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 86.7         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    value_loss           | 432          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 630          |\n",
      "|    ep_rew_mean          | 717          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 344          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 232          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006619142 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.24         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 172          |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.000218    |\n",
      "|    value_loss           | 438          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 635         |\n",
      "|    ep_rew_mean          | 726         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 343         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005654809 |\n",
      "|    clip_fraction        | 0.00801     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    value_loss           | 492         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 626         |\n",
      "|    ep_rew_mean          | 721         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 343         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002063552 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    value_loss           | 413         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 631          |\n",
      "|    ep_rew_mean          | 728          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 343          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 250          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011466645 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 241          |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.000689    |\n",
      "|    value_loss           | 499          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 641          |\n",
      "|    ep_rew_mean          | 741          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 343          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 256          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021351143 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 196          |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    value_loss           | 401          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 640         |\n",
      "|    ep_rew_mean          | 733         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 343         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008407466 |\n",
      "|    clip_fraction        | 0.00498     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 273         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    value_loss           | 423         |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# env = gymnasium.make(\"ALE/Galaxian-v5\" )\n",
    "# model = DQN(\"MlpPolicy\", env, verbose=1, buffer_size=10000 )\n",
    "model.learn(total_timesteps=90000, log_interval=1)\n",
    "model.save(\"PPO_cartpole\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"DQN_cartpole\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "\n",
    "env = gym.make(\"ALE/Galaxian-v5\", render_mode=\"human\")\n",
    "\n",
    "# model = DQN(\"MlpPolicy\", env, verbose=1, buffer_size=10000)\n",
    "# model.learn(total_timesteps=10000, log_interval=4)\n",
    "# model.save(\"dqn_cartpole\")\n",
    "\n",
    "# del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DQN.load(\"DQN_cartpole\")\n",
    "\n",
    "obs, info = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        obs, info = env.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
